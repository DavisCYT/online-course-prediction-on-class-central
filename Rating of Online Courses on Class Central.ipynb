{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9450ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91c512",
   "metadata": {},
   "source": [
    "# Data Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1d6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current edge version is 98.0.1108\n",
      "[WDM] - Get LATEST edgedriver version for 98.0.1108 Edge\n",
      "[WDM] - Trying to download new driver from https://msedgedriver.azureedge.net/98.0.1108.62/edgedriver_mac64.zip\n",
      "[WDM] - Driver has been saved in cache [/Users/yiutongchiu/.wdm/drivers/edgedriver/mac64/98.0.1108.62]\n",
      "<ipython-input-2-1400c5fb7b40>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(EdgeChromiumDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "driver = webdriver.Edge(EdgeChromiumDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec5ece19",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_eng = 'https://www.classcentral.com/subject/cs?lang=english'\n",
    "url_cert = 'https://www.classcentral.com/subject/cs?lang=english&certificate=true'\n",
    "url_beginner = 'https://www.classcentral.com/subject/cs?lang=english&level=beginner'\n",
    "url_interim = 'https://www.classcentral.com/subject/cs?lang=english&level=intermediate'\n",
    "url_advanced = 'https://www.classcentral.com/subject/cs?lang=english&level=advanced'\n",
    "\n",
    "url = {'English' : [url_eng, False],\n",
    "       'Beginner' : [url_beginner, True], \n",
    "       'Intermediate' : [url_interim, True], \n",
    "       'Advanced' : [url_advanced, True], \n",
    "       'With Cert' : [url_cert, True]}\n",
    "\n",
    "# Define the Function Counting How Many Pages to Scrape\n",
    "def total_page(url):\n",
    "    driver.get(url)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    x_path = '//*[@id=\"page-subject\"]/div[1]/div[3]/div[3]/div/span[2]/span/span[contains(@class, \"weight-bold\")]'\n",
    "    num_course = int(driver.find_element(By.XPATH, x_path).text.split()[0].replace(',', ''))\n",
    "    pages = int(math.ceil(num_course / 15))\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de41e74",
   "metadata": {},
   "source": [
    "## Scrape All of the CS Courses in English Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723cb419",
   "metadata": {},
   "source": [
    "## Define the Scraper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b43773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_course(url, url_type, is_type = True):\n",
    "    \n",
    "    courses = []\n",
    "    institutions = []\n",
    "    num_page = total_page(url)\n",
    "    with_type = []\n",
    "    providers = [] # Nominal\n",
    "    workload_dur = [] # Workload + Duration Numeric\n",
    "    ratings = [] # Ordinal\n",
    "    pricing = [] # Ordinal\n",
    "    reviews = [] # Numeric\n",
    "    \n",
    "    if is_type == True:\n",
    "        for num in range(1, num_page + 1):\n",
    "            driver.get(url + '&page=%s' % str(num))\n",
    "            content = driver.page_source\n",
    "            soup = BeautifulSoup(content)\n",
    "        # Extract the Institution, Course Name \n",
    "            for course in soup.find_all('p', {'class' : 'text-2 margin-bottom-xsmall'}):\n",
    "                data_dict = json.loads(course.a.attrs['data-track-props'])['clickMetadata']\n",
    "                institutions.append(data_dict['institution'])\n",
    "                courses.append(data_dict['course'])\n",
    "                with_type.append('Yes')\n",
    "        \n",
    "        df = pd.DataFrame({'Course' : courses, \n",
    "                           'Institution' : institutions, \n",
    "                           url_type : with_type})\n",
    "    \n",
    "    else:\n",
    "        for num in range(1, num_page + 1):\n",
    "            driver.get(url + '&page=%s' % str(num))\n",
    "            content = driver.page_source\n",
    "            soup = BeautifulSoup(content)\n",
    "        # Extract the Institution, Course Name and Provider\n",
    "            for course in soup.find_all('p', {'class' : 'text-2 margin-bottom-xsmall'}):\n",
    "                data_dict = json.loads(course.a.attrs['data-track-props'])['clickMetadata']\n",
    "                institutions.append(data_dict['institution'])\n",
    "                courses.append(data_dict['course'])\n",
    "                providers.append(data_dict['provider'])\n",
    "        # Extract the Rating    \n",
    "            for rate in soup.find_all('span', {'class' : 'cmpt-rating-medium'}):\n",
    "                ratings.append(rate['aria-label'])\n",
    "        # Extract the Pricing      \n",
    "            for price in soup.find_all('span', {'aria-label' : 'Pricing'}):\n",
    "                pricing.append(price.text.strip())\n",
    "        # Extract the Workload and Duration\n",
    "            for ul in soup.find_all('ul', {'class' : 'margin-top-small'}):\n",
    "                if ul.find('span', {'aria-label' : 'Workload and duration'}) is not None:\n",
    "                    workload_dur.append(ul.find('span', {'aria-label' : 'Workload and duration'}).text.strip())\n",
    "                else:\n",
    "                    workload_dur.append(np.nan)\n",
    "        # Extract the Number of Reviews\n",
    "            for a in soup.find_all('a', {'class' : 'hover-no-underline margin-bottom-xxsmall row vert-align-middle'}):\n",
    "                if a.find('span', {'class': 'text-3 color-gray margin-left-xxsmall'}) is not None:\n",
    "                     reviews.append(int(a.find('span', {'class': 'text-3 color-gray margin-left-xxsmall'}).text.strip().split()[0]))\n",
    "                else:\n",
    "                     reviews.append(np.nan)\n",
    "        \n",
    "        df = pd.DataFrame({'Course' : courses, \n",
    "                           'Institution' : institutions, \n",
    "                           'Provider' : providers, \n",
    "                           'Workload_Duration' : workload_dur, \n",
    "                           'Pricing' : pricing, \n",
    "                           'Review' : reviews, \n",
    "                           'Rating' : ratings})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d7359",
   "metadata": {},
   "source": [
    "## Scrape Dataframes of All Courses, Beginner Level Courses, Intermediate Level Courses, Advanced Level Courses and Courses with Cert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab18d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eng = df_course(url_eng, 'English', False) \n",
    "\n",
    "# df_beginner = df_course(url_beginner, 'Beginner', True)\n",
    "\n",
    "# df_interim = df_course(url_interim, 'Intermediate', True)\n",
    "\n",
    "# df_advanced = df_course(url_advanced, 'Advanced', True)\n",
    "\n",
    "# df_cert = df_course(url_cert, 'Cert', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a3676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng, df_beginner, df_interim, df_advanced, df_cert = [df_course(value[0], key, value[1]) for key, value in url.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f11232",
   "metadata": {},
   "source": [
    "## Remove the Duplicated Rows in Each Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the row of each Dataframes by ['Course', 'Institution'] to remove duplicate rows\n",
    "df_eng = df_eng.groupby(['Course', 'Institution']).size().reset_index(name = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beginner = df_beginner.groupby(['Course', 'Institution']).size().reset_index(name = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interim = df_interim.groupby(['Course', 'Institution']).size().reset_index(name = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55047aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advanced = df_advanced.groupby(['Course', 'Institution']).size().reset_index(name = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cert = df_cert.groupby(['Course', 'Institution']).size().reset_index(name = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccefa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_eng, df_beginner, how = 'left', on = ['Course', 'Institution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_i in [df_interim, df_advanced, df_cert]:\n",
    "    df.merge(df_i,  how = 'left', on = ['Course', 'Institution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad5680",
   "metadata": {},
   "source": [
    "# Convert the Data Type of Each Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26849e98",
   "metadata": {},
   "source": [
    "## Remove Rows without Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1 = df1.dropna(subset = ['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7724345",
   "metadata": {},
   "source": [
    "## Convert Rating to Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade644d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list = df1['Rating'].unique().tolist()\n",
    "rating_num = [4.5, 5, 4, 3, 3.5, 2, 0, 1, 1.5]\n",
    "rating_dict = dict(zip(rating_list, rating_num))\n",
    "\n",
    "df1['Rating'] = df1['Rating'].map(rating_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd2528",
   "metadata": {},
   "source": [
    "## Convert Pricing into Categories Free Trail, Free and Paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_list = df1['Pricing'].unique().tolist()\n",
    "\n",
    "def pricing_to_cat(p):\n",
    "    if 'Free Trial' in p:\n",
    "        return 'Free Trial'\n",
    "    elif 'Free Online' in p:\n",
    "        return 'Free'\n",
    "    else:\n",
    "        return 'Paid'\n",
    "\n",
    "pricing_cat = [pricing_to_cat(p) for p in pricing_list]\n",
    "\n",
    "pricing_cat_dict = dict(zip(pricing_list, pricing_cat))\n",
    "\n",
    "df1['Pricing'] = df1['Pricing'].map(pricing_cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c12386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208483f7",
   "metadata": {},
   "source": [
    "### Split Work_Duration Column into Workload and Duration Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Regex to Split \n",
    "work_list = []\n",
    "for i in df1['Workload_Duration']:\n",
    "    if i is np.nan:\n",
    "        i = 'None'\n",
    "        \n",
    "    if re.search(\"hours?\", i) and re.search(\"weeks? long\", i):\n",
    "        work_list.append(i.split(','))\n",
    "    elif re.search(\"hours?\",i):\n",
    "        work_list.append([i, 'None'])\n",
    "    elif re.search(\"weeks?\", i):\n",
    "        work_list.append(['None', i])\n",
    "    else:\n",
    "        work_list.append(['None', 'None'])\n",
    "    \n",
    "# def find_work_dur(x):\n",
    "#     if (:\n",
    "#         return x.split(',')\n",
    "#     elif ('hours' or 'hour') and ('weeks' or 'weeks')in x:\n",
    "#         return ['None' , x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workload = []\n",
    "duration = []\n",
    "for i in work_list:\n",
    "    workload.append(i[0])\n",
    "    duration.append(i[1])\n",
    "#     duration.append(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ba8b6",
   "metadata": {},
   "source": [
    "### Drop Workload_Duration Column and Add Workload and Duration Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Workload'] = workload\n",
    "df1['Duration'] = duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop( columns = 'Workload_Duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71ecbc",
   "metadata": {},
   "source": [
    "### Strip the string of Workload and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Workload']= df1['Workload'].apply(lambda x : x.strip().split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Duration'] = df1['Duration'].apply(lambda x : x.strip().split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac53ae",
   "metadata": {},
   "source": [
    "### Convert the Workload value of a range into the median (2 - 4 hours -> 3 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_med(x):\n",
    "    if '-' in x:\n",
    "        x = (float(x.split('-')[0] )+ float(x.split('-')[1])) / 2\n",
    "    if x == 'None' or x == 'Less':\n",
    "        x = np.nan\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Workload'] = df1['Workload'].apply(lambda x : range_med(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Duration'] = df1['Duration'].apply(lambda x : range_med(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79be9a",
   "metadata": {},
   "source": [
    "### Convert Duration Column to Float and 'None' to numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5517ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Duration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Duration'] = df1['Duration'].apply(lambda x : np.nan if x == 'None' else float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6aad54",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e89c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f33d8f9",
   "metadata": {},
   "source": [
    "## Combine the Same Course with Different Languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36acc0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Provider'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c66428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df1['Institution'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206c4f8",
   "metadata": {},
   "source": [
    "## Deal with Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b677b",
   "metadata": {},
   "source": [
    "### Label Encoding of Provider, Institution and Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fac214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11252f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OrdinalEncoder()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5e466",
   "metadata": {},
   "source": [
    "## Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbdcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b91b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
